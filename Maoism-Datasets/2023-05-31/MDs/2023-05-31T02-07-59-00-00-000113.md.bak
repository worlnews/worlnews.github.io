# 业内高管：AI对人类威胁堪比“大流行病和核战争” (Free Version)

Authors: ['伦敦报道']

Publisher: 英国《金融时报》

Time: 2023-05-31T02:07:59+00:00

Published Time: 2023-05-30T12:00:99+08:00

Modified Time: 2023-05-30T20:33:99+08:00

Description: 人工智能行业350多位高管和研究人员签署的声明称，减轻AI造成灭绝的风险，应该被列为全球优先事项。

Images: []

Themes: ['人工智能']

Keywords: ['人工智能', '科技', '微软', '马斯克']

Type: Article

<!--METADATA-->

来自FT中文网的温馨提示：如您对更多FT中文网的内容感兴趣，请在苹果应用商店或谷歌应用市场搜索“FT中文网”，下载FT中文网的官方应用。

OpenAI和谷歌(Google)DeepMind等公司的一群首席执行官和科学家警告称，快速发展的人工智能(AI)技术对人类构成的潜在威胁与核冲突和疾病不相上下。

“减轻AI造成灭绝的风险，应该与其他社会规模的风险——例如大流行病和核战争——一起被列为全球优先事项，”旧金山非营利组织——人工智能安全中心(Centerfor AI Safety)发布的一份声明称。

包括OpenAI的萨姆•奥尔特曼(Sam Altman)、谷歌DeepMind的德米斯•哈萨比斯(DemisHassabis)和Anthropic的达里奥•阿莫代伊(Dario Amodei)在内的350多位AI高管、研究人员和工程师签署了这份只有一句话的声明。

杰弗里•辛顿(Geoffrey Hinton)和约书亚•本吉奥(Yoshua Bengio)——他们曾因在神经网络领域的工作而获得图灵奖(TuringAward)，经常被称为AI“教父”——也签署了这份声明。辛顿在5月初从谷歌离职，以便不受约束地谈论这项技术的潜在危害。

这份声明出炉之前，大型科技公司发布的一些AI产品提高了人们对其潜在缺陷——包括散布错误信息、固化社会偏见和取代人类员工——的认识，促使各方呼吁对整个行业进行监管。

欧盟立法者正在推进欧洲的《人工智能法案》(Artificial Intelligence Act)，而美国也在探索监管。

微软(Microsoft)支持的OpenAI在去年11月推出ChatGPT，被视为开启AI普及之先河。奥尔特曼5月首次在美国国会作证，呼吁以许可证的形式进行监管。

今年3月，埃隆•马斯克(Elon Musk)等1000多名研究人员和科技公司高管曾呼吁暂停开发先进AI系统六个月，以叫停他们所称的“军备竞赛”。

那封信因其具体做法而受到批评，包括其论证中引用的一些研究人员提出的批评，还有些人则不同意按照该信的建议暂停技术发展。

对于最新这份一句话的声明，人工智能安全中心告诉《纽约时报》(New York Times)，它希望避免分歧。

“我们不想推动包含30种潜在干预措施的庞大菜单，”执行董事丹•亨德里克斯(Dan Hendrycks)表示。“那么做会冲淡主要信息。”

微软首席技术官凯文•斯科特(Kevin Scott)和首席科学官埃里克•霍维茨(EricHorvitz)周二也签署了该声明。签名的还有Deepmind联合创始人、如今经营初创公司Inflection AI的穆斯塔法•苏莱曼(MustafaSuleyman)。

译者/和风

Source: [http://www.ftchinese.com/story/001099811](http://www.ftchinese.com/story/001099811)