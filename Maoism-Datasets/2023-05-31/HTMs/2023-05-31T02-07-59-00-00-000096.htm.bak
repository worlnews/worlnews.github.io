<html>
<head><style>img{height: auto; width: auto\9; width:100%;}</style></head>
<body>
<h1>业内高管：AI对人类威胁堪比“大流行病和核战争” (Free Version)</h1>
<p>Authors: ['伦敦报道']</p>
<p>Publisher: 英国《金融时报》</p>
<p>Time: 2023-05-31T02:07:59+00:00</p>
<p>Published Time: 2023-05-30T12:00:99+08:00</p>
<p>Modified Time: 2023-05-30T20:33:99+08:00</p>
<p>Description: 人工智能行业350多位高管和研究人员签署的声明称，减轻AI造成灭绝的风险，应该被列为全球优先事项。</p>
<p>Images: []</p>
<p>Themes: ['人工智能']</p>
<p>Keywords: ['人工智能', '科技', '微软', '马斯克']</p>
<p>Type: Article</p>
<!--METADATA-->

<p>来自FT中文网的温馨提示：如您对更多FT中文网的内容感兴趣，请在苹果应用商店或谷歌应用市场搜索“FT中文网”，下载FT中文网的官方应用。</p>
<p>OpenAI和谷歌(Google)DeepMind等公司的一群首席执行官和科学家警告称，快速发展的人工智能(AI)技术对人类构成的潜在威胁与核冲突和疾病不相上下。</p>
<p>“减轻AI造成灭绝的风险，应该与其他社会规模的风险——例如大流行病和核战争——一起被列为全球优先事项，”旧金山非营利组织——人工智能安全中心(Centerfor AI Safety)发布的一份声明称。</p>
<p>包括OpenAI的萨姆•奥尔特曼(Sam Altman)、谷歌DeepMind的德米斯•哈萨比斯(DemisHassabis)和Anthropic的达里奥•阿莫代伊(Dario Amodei)在内的350多位AI高管、研究人员和工程师签署了这份只有一句话的声明。</p>
<p>杰弗里•辛顿(Geoffrey Hinton)和约书亚•本吉奥(Yoshua Bengio)——他们曾因在神经网络领域的工作而获得图灵奖(TuringAward)，经常被称为AI“教父”——也签署了这份声明。辛顿在5月初从谷歌离职，以便不受约束地谈论这项技术的潜在危害。</p>
<p>这份声明出炉之前，大型科技公司发布的一些AI产品提高了人们对其潜在缺陷——包括散布错误信息、固化社会偏见和取代人类员工——的认识，促使各方呼吁对整个行业进行监管。</p>
<p>欧盟立法者正在推进欧洲的《人工智能法案》(Artificial Intelligence Act)，而美国也在探索监管。</p>
<p>微软(Microsoft)支持的OpenAI在去年11月推出ChatGPT，被视为开启AI普及之先河。奥尔特曼5月首次在美国国会作证，呼吁以许可证的形式进行监管。</p>
<p>今年3月，埃隆•马斯克(Elon Musk)等1000多名研究人员和科技公司高管曾呼吁暂停开发先进AI系统六个月，以叫停他们所称的“军备竞赛”。</p>
<p>那封信因其具体做法而受到批评，包括其论证中引用的一些研究人员提出的批评，还有些人则不同意按照该信的建议暂停技术发展。</p>
<p>对于最新这份一句话的声明，人工智能安全中心告诉《纽约时报》(New York Times)，它希望避免分歧。</p>
<p>“我们不想推动包含30种潜在干预措施的庞大菜单，”执行董事丹•亨德里克斯(Dan Hendrycks)表示。“那么做会冲淡主要信息。”</p>
<p>微软首席技术官凯文•斯科特(Kevin Scott)和首席科学官埃里克•霍维茨(EricHorvitz)周二也签署了该声明。签名的还有Deepmind联合创始人、如今经营初创公司Inflection AI的穆斯塔法•苏莱曼(MustafaSuleyman)。</p>
<p>译者/和风</p>
<p>Source: <a href="http://www.ftchinese.com/story/001099811">http://www.ftchinese.com/story/001099811</a></p>
</body>
</html>