# 研究：谷歌AI医疗聊天机器人 通过美国医师资格考

Publisher: 法新社

Published Time: 2023-07-13T13:02:07+00:00

Modified Time: 2023-07-13T12:35:02+00:00

Description: （法新社巴黎13日电） 根据昨天的一项同行评审研究，谷歌（Google）的人工智慧（AI）医疗聊天机器人在难度极高的美国USMLE执业医师资格考试中及格，但其答案仍远比不上人类医师。

Videos: []

Images: ["[000000.png](000000.png)"]

<!--METADATA-->

![](../Images/2023-07-13T13-02-07-00-00/000000.png)

去年，Chat GPT由谷歌竞争对手Microsoft（微软）资助的OpenAI开发上市，为科技巨头在快速发展的人工智慧领域竞争拉开序幕。

尽管对于人工智慧未来的可能性和危险性已经引起广泛讨论，但在健康领域，这项技术已经展现了具体进展，包括能够像人类一样解读某些医学扫瞄。

去年12月，谷歌首次在学术着作预印本中，展示了回答医学问题的人工智慧工具Med-PaLM。与Chat GPT不同，谷歌尚未公布于众。

这家美国科技巨头说，Med-PaLM是第一个通过美国医师执照资格考试（USMLE）的大型语言模型，该模型的人工智慧技术透过大量人类生成的文本训练。

这项考试的受试者为美国医学生和受训医师，及格分数约为60分。

在二月，一项研究指出Chat GPT已经达到及格或接近及格的结果。

在昨天发表于自然杂志（journal Nature）的同行评审研究中，谷歌研究人员表示，Med-PaLM在具有美国USMLE执业医师资格考试风格的选择题中取得67.6分。

该研究写道：「Med-PaLM的表现令人鼓舞，但仍比临床医师差。」

为了辨识并减少「错觉」（用于称作AI模型提供错误资讯的情况），谷歌说已经开发一套新的评估指标。

谷歌研究人员及这份新研究报告的主要作者辛格霍（KaranSinghal）告诉法新社，团队已使用这一套评估指标测试他们新版本的模型，并取得了「非常令人兴奋的」结果。

一份发布于5月的学术着作预印本中的研究指出，Med-PaLM 2在美国USMLE执业医师资格考试中取得86.5分，比前一个版本提高了近20%。

未参与研究的英国巴斯大学（University of Bath）电脑科学家达芬波特（JamesDavenport）说，这些人工智慧医疗聊天机器人正面临一个棘手问题，「但人们故意视而不见」。

他表示，「医学问题与实际医学」间存有很大的差异，医学实际上包含诊断和治疗真正的健康问题。

英国里兹大学（Leeds University）人工智慧专家寇恩（AnthonyCohn）说：「错觉大概会永远是这些大型语言模型的问题，因为他们具有统计学上的本质。」

因此，寇恩指出：「这些模型应该始终被视为辅具，而非最终的决策者。」（实习编译：吴冠纬/核稿：陈政一）

Source: [https://www.rfi.fr/cn/%E7%A7%91%E5%AD%A6%E6%96%B0%E7%9F%A5/20230713-%E7%A0%94%E7%A9%B6-%E8%B0%B7%E6%AD%8Cai%E5%8C%BB%E7%96%97%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA-%E9%80%9A%E8%BF%87%E7%BE%8E%E5%9B%BD%E5%8C%BB%E5%B8%88%E8%B5%84%E6%A0%BC%E8%80%83](https://www.rfi.fr/cn/%E7%A7%91%E5%AD%A6%E6%96%B0%E7%9F%A5/20230713-%E7%A0%94%E7%A9%B6-%E8%B0%B7%E6%AD%8Cai%E5%8C%BB%E7%96%97%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA-%E9%80%9A%E8%BF%87%E7%BE%8E%E5%9B%BD%E5%8C%BB%E5%B8%88%E8%B5%84%E6%A0%BC%E8%80%83)