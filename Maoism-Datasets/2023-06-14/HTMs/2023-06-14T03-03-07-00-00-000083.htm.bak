<html>
<head><style>img{height: auto; width: auto\9; width:100%;}</style></head>
<body>
<h1>对AI“踩刹车”式强监管及企业自律恐无法实现 (Free Version)</h1>
<p>Authors: ['']</p>
<p>Publisher: 英国《金融时报》</p>
<p>Time: 2023-06-14T03:03:07+00:00</p>
<p>Published Time: 2023-06-13T12:00:99+08:00</p>
<p>Modified Time: 2023-06-13T22:18:99+08:00</p>
<p>Description: FT中文网总编辑王丰：大语言模型开发者在帮助用户识别AIGC的问题上责无旁贷。社会各界应鼓励、敦促这些机构加速开发并免费向公众提供工具和教育服务。</p>
<p>Images: ["<a href="https://thumbor.ftacademy.cn/unsafe/picture/0/000184020_piclink.jpg">000184020_pic...</a>", "<a href="https://thumbor.ftacademy.cn/unsafe/picture/9/000184299_piclink.jpeg">000184299_pic...</a>", "<a href="https://thumbor.ftacademy.cn/unsafe/picture/0/000184300_piclink.jpeg">000184300_pic...</a>", "<a href="https://thumbor.ftacademy.cn/unsafe/picture/1/000184301_piclink.jpeg">000184301_pic...</a>"]</p>
<p>Themes: ['AI', '关注']</p>
<p>Keywords: ['AI', '人工智能', 'ChatGPT', 'OpenAI', '机器学习', '马斯克']</p>
<p>Type: Article</p>
<!--METADATA-->

<p><img alt="" src="../Images/FT Chinese Free Version/2023-06-14T03-03-07-00-00/000184020_piclink.jpg" />来自FT中文网的温馨提示：如您对更多FT中文网的内容感兴趣，请在苹果应用商店或谷歌应用市场搜索“FT中文网”，下载FT中文网的官方应用。</p>
<p>在大国科技竞争和资本迅速占领AI技术高地的背景下，FT中文网总编辑王丰表示，各界近期呼吁的对AI“踩刹车”式的强监管行动、或企业自觉性限制行动都很难实现，但仍然有可能在几个有限方向上有希望取得进展，比如让平台和用户拥有识别AIGC的工具和能力。</p>
<p>6月8日，华东师范大学教育学部邀请FT中文网总编辑王丰，从AIGC的学习内容来源、机器生成内容迅速充斥流量平台、机器生成内容对机器学习素材的“污染”等角度分析相关风险和应对之道。</p>
<p>以下内容根据现场发言整理。</p>
<p>“人工智能刚刚破解了人类文明的操作系统。”4月29日，以色列历史学家、《未来简史》一书的作者尤瓦尔•诺亚•赫拉利在Frontiers论坛上发出警示，称人工智能目前正在通过掌握语言，给人类带来了生存层面的威胁。因为在赫拉利眼中，语言是文明的基石。OpenAI和谷歌(Google)DeepMind等公司的350多位AI业界高管和研究人员，包括被称为AI“教父”的图灵奖得主杰弗里•辛顿(GeoffreyHinton)和约书亚•本吉奥(YoshuaBengio)均签署声明，将“AI造成灭绝的风险”与“大流行病和核战争”的风险等量齐观。埃隆•马斯克也在今年3月呼吁过暂停开发先进AI系统6个月。</p>
<p>生成式人工智能突飞猛进的发展对于内容行业而言诱惑巨大。像引发孙燕姿本人发文回应的“AI孙燕姿”，不少应用AI生成的多媒体案例已经证明AIGC进入了包括影视、美术、音乐等曾经被人们认为是不可被机器替代的领域，引发了商业、伦理和法律担忧。</p>
<p>与此同时，各国与AI和AIGC相关的法规和监管政策、行业规范都处于动荡和博弈期，现行的规则可能因技术的急剧迭代而迅速过时。</p>
<p>美国版权局（USCO）2023年3月16日发布指引称，人工智能（AI）自动生成的作品不受版权法保护。</p>
<p><img alt="" src="../Images/FT Chinese Free Version/2023-06-14T03-03-07-00-00/000184299_piclink.jpeg" /></p>
<p>最高院知识产权法官周波针对“中国AIGC第一案”，即深圳腾讯公司诉上海盈迅公司案（2019.12.24判决）作出的分析指出，人工智能在著作权上涉及两个法律问题：一是关于“人工智能生成物是否能够成为著作权法保护的作品”，二是“作品著作权的归属”。在该案中，法院认定作品是由人工智能辅助完成的“人类智力活动成果”，而非人工智能自主创造完成，故可以受到著作权法保护。也有法院在判决中特别强调，“自然人创作完成仍应是著作权法上作品的必要条件。”总之，目前中国法院的司法实践而言，人工智能自主生成产物是否能够成为受著作权法保护的作品，还需要做进一步的观察。</p>
<p>内容平台多数仍处于探索、讨论、各自执行阶段。推出聊天机器人Bard试图与OpenAI推出的ChatGPT一较高下的谷歌在AIGC相关指引展现出对机器和人类生成内容一视同仁的态度，并声称会运用SpamBrain等工具协助识别垃圾内容，无论搜索结果是否为AI制造。</p>
<p><img alt="" src="../Images/FT Chinese Free Version/2023-06-14T03-03-07-00-00/000184300_piclink.jpeg" /></p>
<p>维基百科创始人吉米•威尔士（Jimmy Wales）3月30日在The EveningStandard发文称维基百科必须对ChatGPT“无中生有”的倾向非常小心。据Vice报道，该网站背后的非营利组织维基媒体基金会(WikimediaFoundation)正在研究开发工具，让志愿者更容易识别机器人生成的内容。与此同时，维基百科为避免诽谤诉讼和侵犯版权的风险，正在起草一项政策，对志愿者使用大型语言模型创建内容作出限制，指出“任何不熟悉大型语言模型风险的人都应该避免使用它们来创建维基百科内容”。</p>
<p><img alt="" src="../Images/FT Chinese Free Version/2023-06-14T03-03-07-00-00/000184301_piclink.jpeg" /></p>
<p>在音乐版权领域，据《金融时报》5月9日报道，全球最大的音频流媒体业务Spotify近期下架了Boomy上传的约7%的曲目，因为AIGC爆炸式发展能够以及立即生成许多音乐曲目，在线机器人还能大量冒充人类听众夸大歌曲流量，并且引发版权问题。</p>
<p>中国的内容平台近几月陆续针对 AIGC推出成文政策。比对抖音、知乎和百度百家号三个平台的AIGC政策，可以发现几个趋同点：一是强调创作者本人应对其发布的内容负责，平台方将处置包含违法违规、事实性错误的内容；二是发布者应主动添加声明标识，帮助用户辨认哪些内容包含AI辅助创作或是由AI 生成。知乎将禁止批量发布 AIGC类内容的帐号。另外，在抖音和百度百家号平台上，虚拟人账号必须完成实名认证。平台也希望通过自研工具和社区、用户互相监督来识别、管理AIGC。</p>
<p>AIGC对于内容行业尤其是非传统媒体和自媒体而言是巨大诱惑，依靠自律和他律效果有限，而各国现阶段的成文立法均远落后于AIGC技术发展速度。</p>
<p>不过，人类在AI面前并非毫无希望。平台和用户应该也有可能拥有识别AIGC的工具和能力，比如学术机构正在投入新技术防止利用AI剽窃、作弊等行为。OpenAI训练了一个分类工具（classifier）用于区分人类编写的文本和AI编写的文本，但OpenAI也声明该分类工具并不完全可靠，正确识别率仅有26%。AIGC识别工具的能力能否赶上至少在目前看来“道高一丈”的AIGC，实现有效监管，仍未可知。大语言模型开发者在如何帮助用户识别AIGC的问题上责无旁贷。社会各界应鼓励、敦促这些机构加速开发并免费向公众提供便捷、友好的AIGC识别分析工具，并提供相关公众教育服务。</p>
<p>最后，AIGC带来的另一社会风险在于随着AI生成的语料越来越多地进入公众领域，便会成为更多大语言模型训练的素材。当AI开始自己学习自己生成的素材，再生成的文本是否会污染纯人类形成的语料库。这便回到了赫拉利所担忧的起点——因为语言是文明的基石。如果基石已动，人类还能否预计AIGC的演化方向？OpenAI自GPT-4开始已停止公布语料库信息。政府、监管者是否应该强制要求大语言模型开发机构大幅提高训练语料库的透明度？未来不同国家、不同平台在这一方面发展方向、标准、理论动向值得关注。</p>
<p>（仅代表个人观点。整理：袁漪琳。华东师范大学吕离原、叶彤、刘佳渝对本文均有贡献）</p>
<p>Source: <a href="http://www.ftchinese.com/story/001099956">http://www.ftchinese.com/story/001099956</a></p>
</body>
</html>