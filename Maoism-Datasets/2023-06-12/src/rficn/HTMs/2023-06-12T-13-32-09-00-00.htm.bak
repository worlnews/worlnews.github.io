<h1>美AI语音诈骗猖獗　让人防不胜防</h1>
<p>Publisher: 法新社</p>
<p>Published Time: 2023-06-12T-13:32:09+00:00</p>
<p>Modified Time: 2023-06-12T07:05:03+00:00</p>
<p>Description: （法新社华盛顿11日电） 电话那头的声音听来跟真的没两样，美国一名母亲听到「女儿」啜泣求救，之后一名男子接过电话，要求支付赎金。</p>
<p>Videos: []</p>
<p>Images: ["<a href="000000.png">000000.png</a>"]</p>
<!--METADATA-->

<p><img alt="" src="../Images/2023-06-12T-13-32-09-00-00/000000.png" /></p>
<p>但其实女孩的声音来自人工智慧（AI）合成，绑架当然也是假的。</p>
<p>专家表示，AI最大的危险是模糊了真实和虚幻的界线，让网路罪犯能有廉价又有效的技术来散播假讯息。</p>
<p>新型诈骗震撼美国当局，歹徒使用网路上垂手可得、几可乱真的AI语音复制工具，假冒家庭成员来诈骗亲人。</p>
<p>住在亚利桑那州的迪斯特法诺（Jennifer DeStefano）听到电话那头传来：「救我，妈，救我。」</p>
<p>迪斯特法诺「100%」确定那是她15岁的女儿在滑雪时陷入麻烦。</p>
<p>迪斯特法诺4月告诉当地电视台：「问题不是那是谁，那就是她的声音…她哭起来就是那样。」</p>
<p>在美国等9个国家针对7000人的民调中，1/4表示自己遇过AI语音诈骗，或听过别人有类似经验。</p>
<p>这份由美国资安公司迈克菲实验室（McAfee Labs）上月发布的民调显示，70%受访者表示，没有信心能「分辨真假语音」。</p>
<p>加州大学柏克莱分校资讯学院教授法瑞德（Hany Farid）告诉法新社：「因为现在制作高仿真的语音非常容易…网路上几乎无人能幸免。这些诈骗正广为流行。」</p>
<p>Source: <a href="https://www.rfi.fr/cn/%E7%BC%A4%E7%BA%B7%E4%B8%96%E7%95%8C/20230612-%E7%BE%8Eai%E8%AF%AD%E9%9F%B3%E8%AF%88%E9%AA%97%E7%8C%96%E7%8D%97-%E8%AE%A9%E4%BA%BA%E9%98%B2%E4%B8%8D%E8%83%9C%E9%98%B2">https://www.rfi.fr/cn/%E7%BC%A4%E7%BA%B7%E4%B8%96%E7%95%8C/20230612-%E7%BE%8Eai%E8%AF%AD%E9%9F%B3%E8%AF%88%E9%AA%97%E7%8C%96%E7%8D%97-%E8%AE%A9%E4%BA%BA%E9%98%B2%E4%B8%8D%E8%83%9C%E9%98%B2</a></p>